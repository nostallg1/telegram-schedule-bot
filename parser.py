import requests
from bs4 import BeautifulSoup
import logging
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BASE_URL = "https://student.lpnu.ua"

# --- –§—É–Ω–∫—Ü—ñ—è –µ–∫—Ä–∞–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –¥–Ω—è (–±–µ–∑ –∑–º—ñ–Ω) ---
def escape_markdown(text):
    """
    –ï–∫—Ä–∞–Ω—É—î –≤—Å—ñ MarkdownV2 —Å–∏–º–≤–æ–ª–∏, —è–∫—ñ –º–æ–∂—É—Ç—å –±—É—Ç–∏ –≤ –Ω–∞–∑–≤–∞—Ö –ø—Ä–µ–¥–º–µ—Ç—ñ–≤.
    """
    text = re.sub(r'([.()\[\]-])', r'\\\1', text)
    text = re.sub(r'([~`>#=+|\{}!])', r'\\\1', text)
    return text.replace('_', r'\_').replace('*', r'\*')

DAY_MAP = {
    "–ü–æ–Ω–µ–¥—ñ–ª–æ–∫": ["–ø–Ω", "–ø–æ–Ω", "mon"],
    "–í—ñ–≤—Ç–æ—Ä–æ–∫":  ["–≤—Ç", "–≤—ñ–≤", "bt", "vt", "tue"],
    "–°–µ—Ä–µ–¥–∞":    ["—Å—Ä", "—Å–µ—Ä", "cp", "wed"],
    "–ß–µ—Ç–≤–µ—Ä":    ["—á—Ç", "—á–µ—Ç", "thu"],
    "–ü'—è—Ç–Ω–∏—Ü—è":  ["–ø—Ç", "–ø—è—Ç", "fri"],
    "–°—É–±–æ—Ç–∞":    ["—Å–±", "—Å—É–±", "sat"],
    "–ù–µ–¥—ñ–ª—è":    ["–Ω–¥", "–Ω–µ–¥", "sun"]
}

def get_standard_day_name(line):
    clean_line = re.sub(r'[^\w]', '', line).lower()
    
    for standard_name, variants in DAY_MAP.items():
        for variant in variants:
            if clean_line.startswith(variant):
                return standard_name
    return None

def fetch_schedule_dict(group_name, semester="1", duration="1", subgroup=None):
    schedule_url = f"{BASE_URL}/students_schedule"
    params = {
        "studygroup_abbrname": group_name,
        "semestr": semester,
        "semestrduration": duration
    }

    try:
        # --- –ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–õ–ò–í–ê –ó–ú–Ü–ù–ê: –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏ ---
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'uk-UA,uk;q=0.9,en-US;q=0.8,en;q=0.7',
            'Connection': 'keep-alive',
        }
        
        # requests.get –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø—ñ–¥—Ç—Ä–∏–º—É—î –¥–æ 30 –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω—å. –ú–∏ –ø–æ–∫–ª–∞–¥–∞—î–º–æ—Å—è –Ω–∞ —Ç–µ,
        # —â–æ –Ω–æ–≤—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∑–ª–∞–º–∞—é—Ç—å —Ü–∏–∫–ª –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω—å.
        response = requests.get(schedule_url, params=params, headers=headers, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')
        content_div = soup.find('div', class_='view-content')
        
        if not content_div:
            if "–Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ" in soup.text.lower():
                return {"Info": f"‚ùå –ì—Ä—É–ø—É **{group_name}** –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."}
            return {"Info": "‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —Ä–æ–∑–∫–ª–∞–¥. –°–∞–π—Ç –ø–æ–≤–µ—Ä–Ω—É–≤ –Ω–µ–∑—Ä–æ–∑—É–º—ñ–ª—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å."}

        schedule_data = {} 
        
        # --- –°–ü–†–û–ë–ê 1: HTML –ë–ª–æ–∫–∏ ---
        days = content_div.find_all('div', class_='view-grouping')
        # ... (–ª–æ–≥—ñ–∫–∞ –æ–±—Ä–æ–±–∫–∏ HTML –±–ª–æ–∫—ñ–≤, –∑–∞–ª–∏—à–µ–Ω–∞ –±–µ–∑ –∑–º—ñ–Ω)
        if days:
            for day_block in days:
                header = day_block.find('span', class_='view-grouping-header')
                raw_day = header.get_text(strip=True) if header else "–Ü–Ω—à–µ"
                day_name = get_standard_day_name(raw_day)
                if not day_name: continue 
                
                day_text = f"üìÖ *{day_name}* ({group_name})\n\n"
                has_pairs = False
                
                rows = day_block.find_all('div', class_='stud_schedule')
                for row in rows:
                    num_header = row.find_previous('h3')
                    pair_num = num_header.get_text(strip=True) if num_header else "?"
                    
                    content = row.find('div', class_='group_content')
                    if not content: content = row
                    full_pair_text = content.get_text(separator=" ", strip=True).strip()

                    if subgroup:
                        excluded_subgroup = str(3 - int(subgroup))
                        if re.search(f"(–ø—ñ–¥–≥—Ä\. {excluded_subgroup})", full_pair_text, re.IGNORECASE) or \
                           re.search(f"(\({excluded_subgroup}\))", full_pair_text):
                            continue
                            
                    day_text += f"‚è∞ *{pair_num} –ø–∞—Ä–∞*\nüìñ {escape_markdown(full_pair_text)}\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
                    has_pairs = True
                
                if has_pairs:
                    schedule_data[day_name] = day_text

        # --- –°–ü–†–û–ë–ê 2: –¢–µ–∫—Å—Ç–æ–≤–∏–π –ø–∞—Ä—Å–∏–Ω–≥ ---
        if not schedule_data:
            # ... (–ª–æ–≥—ñ–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É, –∑–∞–ª–∏—à–µ–Ω–∞ –±–µ–∑ –∑–º—ñ–Ω)
            raw_text = content_div.get_text(separator="\n", strip=True)
            lines = [line.strip() for line in raw_text.split('\n') if line.strip()]
            
            current_day = None
            temp_schedule = {}
            day_start_pattern = re.compile(r'^(–ü–æ–Ω–µ–¥—ñ–ª–æ–∫|–í—ñ–≤—Ç–æ—Ä–æ–∫|–°–µ—Ä–µ–¥–∞|–ß–µ—Ç–≤–µ—Ä|–ü\'—è—Ç–Ω–∏—Ü—è|–°—É–±–æ—Ç–∞|–ù–µ–¥—ñ–ª—è|–ü–Ω|–í—Ç|–°—Ä|–ß—Ç|–ü—Ç|–°–±|–ù–¥)\b', re.IGNORECASE)

            for line in lines:
                detected_match = day_start_pattern.match(line)
                if detected_match:
                    day_part = detected_match.group(0)
                    detected_day = get_standard_day_name(day_part)
                    
                    if detected_day:
                        current_day = detected_day
                        if current_day not in temp_schedule:
                            temp_schedule[current_day] = []
                        
                        remainder = line[len(day_part):].strip()
                        if remainder and re.match(r'^[1-8]$', remainder.split()[0]):
                            pair_num = remainder.split()[0]
                            temp_schedule[current_day].append({'num': pair_num, 'text': remainder[len(pair_num):].strip()})
                        continue

                if current_day and re.match(r'^[1-8]$', line):
                    temp_schedule[current_day].append({'num': line, 'text': ""})
                    continue

                if current_day and current_day in temp_schedule and temp_schedule[current_day]:
                    last_pair = temp_schedule[current_day][-1]
                    last_pair['text'] += ("\n" if last_pair['text'] else "") + line

            # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            for day, pairs in temp_schedule.items():
                day_text = f"üìÖ *{day}* ({group_name})\n\n"
                has_pairs_in_day = False
                
                for pair in pairs:
                    full_text = pair['text']
                    
                    if subgroup:
                        excluded_subgroup = str(3 - int(subgroup))
                        if re.search(f"(–ø—ñ–¥–≥—Ä\. {excluded_subgroup})", full_text, re.IGNORECASE) or \
                           re.search(f"(\({excluded_subgroup}\))", full_text):
                            continue
                    
                    escaped_text = escape_markdown(full_text)
                    
                    day_text += f"‚è∞ *{pair['num']} –ø–∞—Ä–∞*\nüìñ {escaped_text}\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
                    has_pairs_in_day = True
                
                if has_pairs_in_day:
                    schedule_data[day] = day_text

        if not schedule_data:
            return {"Info": "üì≠ –†–æ–∑–∫–ª–∞–¥ –ø–æ—Ä–æ–∂–Ω—ñ–π (–∞–±–æ –≤–∏—Ö—ñ–¥–Ω—ñ)."}

        return schedule_data

    except requests.exceptions.TooManyRedirects:
        logger.error("Exceeded 30 redirects (Site blocking bot).")
        return {"Info": "üõë –ü–æ–º–∏–ª–∫–∞. –°–∞–π—Ç —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç—É –∑–∞–±–ª–æ–∫—É–≤–∞–≤ –∑–∞–ø–∏—Ç (–∑–∞—Ö–∏—Å—Ç –≤—ñ–¥ –±–æ—Ç—ñ–≤). –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ."}
    except Exception as e:
        logger.error(f"Parser Error: {e}", exc_info=True)
        return {"Info": "‚ö†Ô∏è –ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞."}

