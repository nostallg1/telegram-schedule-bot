import requests
from bs4 import BeautifulSoup
import logging
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BASE_URL = "https://student.lpnu.ua"

def normalize_text(text):
    """
    –ê–≥—Ä–µ—Å–∏–≤–Ω–∞ –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç—É.
    –ó–∞–º—ñ–Ω—é—î –≤—Å—ñ —Å—Ö–æ–∂—ñ –ª–∞—Ç–∏–Ω—Å—å–∫—ñ –ª—ñ—Ç–µ—Ä–∏ –Ω–∞ –∫–∏—Ä–∏–ª–∏—Ü—é.
    """
    if not text: return ""
    
    # –†–æ–∑—à–∏—Ä–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –∑–∞–º—ñ–Ω
    replacements = {
        'A': '–ê', 'B': '–í', 'C': '–°', 'E': '–ï', 'H': '–ù', 'I': '–Ü', 'K': '–ö',
        'M': '–ú', 'O': '–û', 'P': '–†', 'T': '–¢', 'X': '–•', 'Y': '–£',
        'a': '–∞', 'c': '—Å', 'e': '–µ', 'i': '—ñ', 'k': '–∫', 'o': '–æ', 'p': '—Ä', 'x': '—Ö',
        'y': '—É', 't': '—Ç' # –î–æ–¥–∞–Ω–æ 't', —è–∫–∞ —á–∞—Å—Ç–æ –ª–∞–º–∞—î '–í—ñ–≤—Ç–æ—Ä–æ–∫'
    }
    
    clean = text.strip()
    for lat, cyr in replacements.items():
        clean = clean.replace(lat, cyr)
    return clean

def get_day_from_string(line):
    """
    –í–∏–∑–Ω–∞—á–∞—î –¥–µ–Ω—å —Ç–∏–∂–Ω—è –∑–∞ –ø–æ—á–∞—Ç–∫–æ–º —Å–ª–æ–≤–∞ (–Ω–µ—á—ñ—Ç–∫–∏–π –ø–æ—à—É–∫).
    –ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω—É –Ω–∞–∑–≤—É –¥–Ω—è –∞–±–æ None.
    """
    line = normalize_text(line).lower()
    
    # –°–ª–æ–≤–Ω–∏–∫ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ: {–≤–∞—Ä—ñ–∞–Ω—Ç–∏_–ø–æ—á–∞—Ç–∫—É: –ø–æ–≤–Ω–∞_–Ω–∞–∑–≤–∞}
    days_map = {
        ('–ø–Ω', '–ø–æ–Ω'): "–ü–æ–Ω–µ–¥—ñ–ª–æ–∫",
        ('–≤—Ç', '–≤—ñ–≤'): "–í—ñ–≤—Ç–æ—Ä–æ–∫",
        ('—Å—Ä', '—Å–µ—Ä'): "–°–µ—Ä–µ–¥–∞",
        ('—á—Ç', '—á–µ—Ç'): "–ß–µ—Ç–≤–µ—Ä",
        ('–ø—Ç', '–ø\'—è', '–ø—è'): "–ü'—è—Ç–Ω–∏—Ü—è",
        ('—Å–±', '—Å—É–±'): "–°—É–±–æ—Ç–∞",
        ('–Ω–¥', '–Ω–µ–¥'): "–ù–µ–¥—ñ–ª—è"
    }
    
    for prefixes, full_name in days_map.items():
        if line.startswith(prefixes):
            return full_name
            
    return None

def fetch_schedule_dict(group_name, semester="1", duration="1", subgroup=None):
    schedule_url = f"{BASE_URL}/students_schedule"
    params = {
        "studygroup_abbrname": group_name,
        "semestr": semester,
        "semestrduration": duration
    }

    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(schedule_url, params=params, headers=headers)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')
        content_div = soup.find('div', class_='view-content')
        
        if not content_div:
            if "–Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ" in soup.text.lower():
                return {"Info": f"‚ùå –ì—Ä—É–ø—É **{group_name}** –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."}
            return {"Info": "‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —Ä–æ–∑–∫–ª–∞–¥."}

        schedule_data = {} 

        # --- –í–ê–†–Ü–ê–ù–¢ 1: HTML –ë–ª–æ–∫–∏ (view-grouping) ---
        days = content_div.find_all('div', class_='view-grouping')
        if days:
            for day_block in days:
                header = day_block.find('span', class_='view-grouping-header')
                raw_day = header.get_text(strip=True) if header else "–Ü–Ω—à–µ"
                # –í–∏–∑–Ω–∞—á–∞—î–º–æ –Ω–æ—Ä–º–∞–ª—å–Ω—É –Ω–∞–∑–≤—É –¥–Ω—è
                day_name = get_day_from_string(raw_day) or raw_day
                
                day_text = f"üìÖ *{day_name}* ({group_name})\n\n"
                has_pairs = False
                
                rows = day_block.find_all('div', class_='stud_schedule')
                for row in rows:
                    num_header = row.find_previous('h3')
                    pair_num = num_header.get_text(strip=True) if num_header else "?"
                    
                    content = row.find('div', class_='group_content')
                    if not content: content = row
                    full_pair_text = normalize_text(content.get_text(separator=" ", strip=True))

                    if subgroup:
                        if f"–ø—ñ–¥–≥—Ä. {3-int(subgroup)}" in full_pair_text.lower() or \
                           f"–ø—ñ–¥–≥—Ä—É–ø–∞ {3-int(subgroup)}" in full_pair_text.lower():
                            continue

                    day_text += f"‚è∞ *{pair_num} –ø–∞—Ä–∞*\nüìñ {full_pair_text}\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
                    has_pairs = True
                
                if has_pairs:
                    schedule_data[day_name] = day_text

        # --- –í–ê–†–Ü–ê–ù–¢ 2: –¢–µ–∫—Å—Ç–æ–≤–∏–π –ø–∞—Ä—Å–∏–Ω–≥ (—è–∫—â–æ HTML –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–≤ –∞–±–æ –Ω–µ–ø–æ–≤–Ω–∏–π) ---
        if not schedule_data:
            raw_text = content_div.get_text(separator="\n", strip=True)
            lines = [line.strip() for line in raw_text.split('\n') if line.strip()]
            
            current_day = None
            temp_schedule = {}

            for line in lines:
                # 1. –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ü–µ –¥–µ–Ω—å —Ç–∏–∂–Ω—è (—á–µ—Ä–µ–∑ –Ω–∞—à—É —Ä–æ–∑—É–º–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é)
                detected_day = get_day_from_string(line)
                if detected_day:
                    current_day = detected_day
                    temp_schedule[current_day] = []
                    continue
                
                # 2. –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ü–µ –Ω–æ–º–µ—Ä –ø–∞—Ä–∏ (—Ü–∏—Ñ—Ä–∞ 1-8)
                if current_day and re.match(r'^[1-8]$', line):
                    # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—É –ø–∞—Ä—É
                    temp_schedule[current_day].append({'num': line, 'text': ""})
                    continue

                # 3. –¢–µ–∫—Å—Ç –ø–∞—Ä–∏
                if current_day and temp_schedule[current_day]:
                    last_pair = temp_schedule[current_day][-1]
                    last_pair['text'] += ("\n" if last_pair['text'] else "") + normalize_text(line)

            # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            for day, pairs in temp_schedule.items():
                day_text = f"üìÖ *{day}* ({group_name})\n\n"
                has_pairs_in_day = False
                
                for pair in pairs:
                    full_text = pair['text']
                    if subgroup:
                        if f"–ø—ñ–¥–≥—Ä. {3-int(subgroup)}" in full_text.lower() or \
                           f"–ø—ñ–¥–≥—Ä—É–ø–∞ {3-int(subgroup)}" in full_text.lower():
                            continue
                    
                    day_text += f"‚è∞ *{pair['num']} –ø–∞—Ä–∞*\nüìñ {full_text}\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
                    has_pairs_in_day = True
                
                if has_pairs_in_day:
                    schedule_data[day] = day_text

        if not schedule_data:
            return {"Info": "üì≠ –†–æ–∑–∫–ª–∞–¥ –ø–æ—Ä–æ–∂–Ω—ñ–π (–∞–±–æ –≤–∏—Ö—ñ–¥–Ω—ñ)."}

        return schedule_data

    except Exception as e:
        logger.error(f"Parser Error: {e}")
        return {"Info": "‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞."}

