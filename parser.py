import requests
from bs4 import BeautifulSoup
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BASE_URL = "https://student.lpnu.ua"

def fetch_schedule_dict(group_name, semester="1", duration="1", subgroup=None):
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ª–æ–≤–Ω–∏–∫: {'–ü–æ–Ω–µ–¥—ñ–ª–æ–∫': '—Ç–µ–∫—Å—Ç —Ä–æ–∑–∫–ª–∞–¥—É', ...}
    """
    schedule_url = f"{BASE_URL}/students_schedule"
    params = {
        "studygroup_abbrname": group_name,
        "semestr": semester,
        "semestrduration": duration
    }

    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(schedule_url, params=params, headers=headers)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')
        content_div = soup.find('div', class_='view-content')
        
        if not content_div:
            if "–Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ" in soup.text.lower():
                return {"Info": f"‚ùå –ì—Ä—É–ø—É **{group_name}** –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."}
            return {"Info": "‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ —Ä–æ–∑–∫–ª–∞–¥. –ú–æ–∂–ª–∏–≤–æ, —Å–∞–π—Ç –∑–º—ñ–Ω–∏–≤—Å—è."}

        days = content_div.find_all('div', class_='view-grouping')
        schedule_data = {} 

        # –Ø–∫—â–æ –±–ª–æ–∫—ñ–≤ –¥–Ω—ñ–≤ –Ω–µ–º–∞—î, –∞–ª–µ —î —Ç–µ–∫—Å—Ç (–Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –≤–∏–≥–ª—è–¥)
        if not days:
            raw_text = content_div.get_text(separator="\n", strip=True)
            if len(raw_text) > 20:
                 # –Ø–∫—â–æ –º–∏ –Ω–µ –º–æ–∂–µ–º–æ —Ä–æ–∑–±–∏—Ç–∏ –ø–æ –¥–Ω—è—Ö, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ —è–∫ "–ó–∞–≥–∞–ª—å–Ω–∏–π"
                 return {"–ó–∞–≥–∞–ª—å–Ω–∏–π —Ä–æ–∑–∫–ª–∞–¥": f"‚ö†Ô∏è –ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç:\n\n{raw_text[:3000]}"}
            return {"Info": "üì≠ –†–æ–∑–∫–ª–∞–¥ –ø–æ—Ä–æ–∂–Ω—ñ–π."}

        for day_block in days:
            header = day_block.find('span', class_='view-grouping-header')
            day_name = header.get_text(strip=True) if header else "–Ü–Ω—à–µ"
            
            day_text = f"üìÖ *{day_name}* ({group_name})\n\n"
            has_pairs = False
            
            rows = day_block.find_all('div', class_='stud_schedule')
            
            for row in rows:
                num_header = row.find_previous('h3')
                pair_num = num_header.get_text(strip=True) if num_header else "?"
                
                content = row.find('div', class_='group_content')
                if not content: content = row
                
                full_pair_text = content.get_text(separator=" ", strip=True)

                # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –ø—ñ–¥–≥—Ä—É–ø–∏
                if subgroup:
                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î (–ø—ñ–¥–≥—Ä. 1) –∞–±–æ [1] –≤ —Ç–µ–∫—Å—Ç—ñ
                    if f"–ø—ñ–¥–≥—Ä. {3-int(subgroup)}" in full_pair_text.lower() or \
                       f"–ø—ñ–¥–≥—Ä—É–ø–∞ {3-int(subgroup)}" in full_pair_text.lower():
                        continue
                
                day_text += f"‚è∞ *{pair_num} –ø–∞—Ä–∞*\nüìñ {full_pair_text}\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
                has_pairs = True
            
            if has_pairs:
                schedule_data[day_name] = day_text

        if not schedule_data:
            return {"Info": "üéâ –ü–∞—Ä –Ω–µ–º–∞—î (–∞–±–æ –≤–æ–Ω–∏ –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω—ñ)."}

        return schedule_data

    except Exception as e:
        logger.error(f"Parser Error: {e}")
        return {"Info": "‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞."}


