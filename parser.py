import requests
from bs4 import BeautifulSoup
import logging
import re
import time
import random
import os
import html

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BASE_URL = "https://student.lpnu.ua"
SCRAPER_API_KEY = os.environ.get('SCRAPER_API_KEY', None)

# --- CONFIG ---
DAY_MAP = {
    "–ü–æ–Ω–µ–¥—ñ–ª–æ–∫": ["–ø–Ω", "–ø–æ–Ω", "mon"],
    "–í—ñ–≤—Ç–æ—Ä–æ–∫":  ["–≤—Ç", "–≤—ñ–≤", "bt", "vt", "tue"],
    "–°–µ—Ä–µ–¥–∞":    ["—Å—Ä", "—Å–µ—Ä", "cp", "wed"],
    "–ß–µ—Ç–≤–µ—Ä":    ["—á—Ç", "—á–µ—Ç", "thu"],
    "–ü'—è—Ç–Ω–∏—Ü—è":  ["–ø—Ç", "–ø—è—Ç", "fri"],
    "–°—É–±–æ—Ç–∞":    ["—Å–±", "—Å—É–±", "sat"],
    "–ù–µ–¥—ñ–ª—è":    ["–Ω–¥", "–Ω–µ–¥", "sun"]
}

def get_standard_day_name(line):
    clean_line = re.sub(r'[^\w]', '', line).lower()
    for standard_name, variants in DAY_MAP.items():
        for variant in variants:
            if clean_line.startswith(variant):
                return standard_name
    return None

# --- –ó–ê–ü–ò–¢ ---
def make_request(group_name, semester, duration):
    schedule_url = f"{BASE_URL}/students_schedule"
    params = {
        "studygroup_abbrname": group_name,
        "semestr": semester,
        "semestrduration": duration
    }
    
    if SCRAPER_API_KEY:
        payload = {
            'api_key': SCRAPER_API_KEY,
            'url': schedule_url + '?' + requests.compat.urlencode(params),
            'render': 'true' # –í–∞–∂–ª–∏–≤–æ –¥–ª—è JS
        }
        response = requests.get('http://api.scraperapi.com', params=payload, timeout=60)
    else:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': BASE_URL + '/',
        }
        time.sleep(1 + random.random())
        with requests.Session() as session:
            session.headers.update(headers)
            response = session.get(schedule_url, params=params, timeout=15)
            
    return response

# --- –ü–ê–†–°–ï–† ---
def fetch_schedule_dict(group_name, semester="1", duration="1", subgroup=None, week_filter=None):
    
    # 1. –ó–∞–ø–∏—Ç (–ü–µ—Ä—à–∞ –ø–æ–ª–æ–≤–∏–Ω–∞)
    try:
        response = make_request(group_name, semester, "1")
        if response.status_code != 200: return {"Info": f"‚ùå HTTP Error {response.status_code}"}
    except Exception as e:
        return {"Info": "‚ùå –ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è."}

    soup = BeautifulSoup(response.text, 'html.parser')
    content_div = soup.find('div', class_='view-content')

    # 2. –Ø–∫—â–æ –ø—É—Å—Ç–æ -> –î—Ä—É–≥–∞ –ø–æ–ª–æ–≤–∏–Ω–∞ (Duration=2)
    if not content_div or not content_div.get_text(strip=True):
        try:
            response_2 = make_request(group_name, semester, "2")
            if response_2.status_code == 200:
                soup_2 = BeautifulSoup(response_2.text, 'html.parser')
                if soup_2.find('div', class_='view-content'):
                    soup = soup_2
                    content_div = soup.find('div', class_='view-content')
        except: pass

    if not content_div:
        if "–Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ" in soup.text.lower():
            return {"Info": f"‚ùå –ì—Ä—É–ø—É <b>{html.escape(group_name)}</b> –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."}
        # DEBUG: –Ø–∫—â–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É –Ω–µ–º–∞—î, –ø–æ–∫–∞–∂–µ–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–æ—Ä—ñ–Ω–∫–∏
        title = soup.title.string if soup.title else "No Title"
        return {"Info": f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–∞–Ω—ñ. –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–æ—Ä—ñ–Ω–∫–∏: {title}"}

    schedule_data = {} 

    # --- –§—ñ–ª—å—Ç—Ä –ø—ñ–¥–≥—Ä—É–ø ---
    def is_excluded_subgroup(text, current_subgroup):
        if not current_subgroup: return False
        ex_sub = str(3 - int(current_subgroup))
        patterns = [f"\({ex_sub}\)", f"–ø—ñ–¥–≥—Ä\.\s*{ex_sub}", f"{ex_sub}\s*–ø/–≥", f"–ø—ñ–¥–≥—Ä—É–ø–∞\s*{ex_sub}"]
        text_lower = text.lower()
        for p in patterns:
            if re.search(p, text_lower, re.IGNORECASE):
                our_sub = str(current_subgroup)
                if not re.search(f"\({our_sub}\)", text_lower): return True 
        return False

    # --- –§—ñ–ª—å—Ç—Ä —Ç–∏–∂–Ω—ñ–≤ ---
    def is_excluded_week(classes_list, current_filter):
        if not current_filter: return False
        cls = set(classes_list)
        is_chys = 'chys' in cls or 'week_1' in cls
        is_znam = 'znam' in cls or 'week_2' in cls
        if current_filter == 'chys' and is_znam and not is_chys: return True
        if current_filter == 'znam' and is_chys and not is_znam: return True
        return False

    # === –í–ê–†–Ü–ê–ù–¢ 1: HTML ===
    days = content_div.find_all('div', class_='view-grouping')
    if days:
        for day_block in days:
            header = day_block.find('span', class_='view-grouping-header')
            raw_day = header.get_text(strip=True) if header else ""
            day_name = get_standard_day_name(raw_day)
            if not day_name: continue 
            
            day_text = f"üìÖ <b>{day_name}</b> ({html.escape(group_name)})\n\n"
            has_pairs = False
            
            rows = day_block.find_all('div', class_='stud_schedule')
            for row in rows:
                if is_excluded_week(row.get('class', []), week_filter): continue

                num_header = row.find_previous('h3')
                pair_num = num_header.get_text(strip=True) if num_header else "?"
                
                content = row.find('div', class_='group_content')
                if not content: content = row
                full_pair_text = content.get_text(separator=" ", strip=True).strip()

                if is_excluded_subgroup(full_pair_text, subgroup): continue
                
                safe_text = html.escape(full_pair_text)
                classes = row.get('class', [])
                week_mark = " <i>(—á–∏—Å.)</i>" if ('chys' in classes or 'week_1' in classes) else (" <i>(–∑–Ω–∞–º.)</i>" if ('znam' in classes or 'week_2' in classes) else "")

                day_text += f"‚è∞ <b>{pair_num} –ø–∞—Ä–∞</b>{week_mark}\nüìñ {safe_text}\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
                has_pairs = True
            
            if has_pairs:
                schedule_data[day_name] = day_text

    # === –í–ê–†–Ü–ê–ù–¢ 2: –¢–µ–∫—Å—Ç (Fallback) ===
    if not schedule_data:
        raw_text = content_div.get_text(separator="\n", strip=True)
        lines = [line.strip() for line in raw_text.split('\n') if line.strip()]
        current_day = None
        temp_schedule = {}
        
        day_pattern = re.compile(r'^(–ü–æ–Ω–µ–¥—ñ–ª–æ–∫|–í—ñ–≤—Ç–æ—Ä–æ–∫|–°–µ—Ä–µ–¥–∞|–ß–µ—Ç–≤–µ—Ä|–ü\'—è—Ç–Ω–∏—Ü—è|–°—É–±–æ—Ç–∞|–ù–µ–¥—ñ–ª—è|–ü–Ω|–í—Ç|–°—Ä|–ß—Ç|–ü—Ç|–°–±|–ù–¥)\b', re.IGNORECASE)

        for line in lines:
            match = day_pattern.match(line)
            if match:
                current_day = get_standard_day_name(match.group(0))
                if current_day and current_day not in temp_schedule: temp_schedule[current_day] = []
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ "–ü–Ω 1 –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞"
                rem = line[len(match.group(0)):].strip()
                if rem and re.match(r'^[1-8]', rem):
                     temp_schedule[current_day].append({'num': rem[0], 'text': rem[1:].strip()})
                continue
            
            if current_day and re.match(r'^[1-8][\.\)\s]?', line):
                pair_num = line[0]
                text = line[1:].strip(" .)")
                temp_schedule[current_day].append({'num': pair_num, 'text': text})
                continue
            
            if current_day and current_day in temp_schedule and temp_schedule[current_day]:
                temp_schedule[current_day][-1]['text'] += " " + line

        for day, pairs in temp_schedule.items():
            day_text = f"üìÖ <b>{day}</b> ({html.escape(group_name)})\n\n"
            has = False
            for p in pairs:
                if is_excluded_subgroup(p['text'], subgroup): continue
                day_text += f"‚è∞ <b>{p['num']} –ø–∞—Ä–∞</b>\nüìñ {html.escape(p['text'])}\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
                has = True
            if has: schedule_data[day] = day_text

    if not schedule_data:
        # --- –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê ---
        # –ú–∏ –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ —à–º–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç—É, —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏, –©–û –°–ê–ú–ï —Ç–∞–º –Ω–∞–ø–∏—Å–∞–Ω–æ
        raw_preview = content_div.get_text(separator="\n", strip=True)[:400]
        return {"Info": f"üì≠ –†–æ–∑–∫–ª–∞–¥ –ø–æ—Ä–æ–∂–Ω—ñ–π. –û—Å—å —â–æ –±–∞—á–∏—Ç—å –±–æ—Ç:\n\n<pre>{html.escape(raw_preview)}</pre>"}

    return schedule_data


